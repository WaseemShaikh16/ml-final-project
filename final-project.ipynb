{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final Project\n",
    "\n",
    "Zohair\n",
    "Waseem\n",
    "Pramod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the labeled dataset\n",
    "# Annotate the dataset\n",
    "# Preprocessing\n",
    "# Slang handling\n",
    "\n",
    "# Feature Extraction\n",
    "\n",
    "# Model training\n",
    "\n",
    "# Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cid': 'UgyOf9mk6fIifJlhlrt4AaABAg', 'text': 'Anyone else fricking depressed now that this is all over?', 'time': '3 years ago', 'author': '@gokussupersaiyan', 'channel': 'UCbk7dmSDthf2ER95Qc2e9rg', 'votes': '16K', 'photo': 'https://yt3.ggpht.com/ytc/AOPolaTdeKE9ceUSoCQHj1GhIgW6TJ-VXjPjnPpwfZsXpQ=s176-c-k-c0x00ffffff-no-rj', 'heart': False, 'reply': False, 'time_parsed': 1597436467.682756}\n",
      "{'cid': 'Ugy3IZohv4ykY-k4k4B4AaABAg', 'text': \"Infinity War was such a legendary movie that people come to rewatch it's trailer 3 years after its release.\", 'time': '1 year ago', 'author': '@darthnihilus1052', 'channel': 'UCwEuZxI0os6Nszm0OWleU8A', 'votes': '22K', 'photo': 'https://yt3.ggpht.com/hFhy-Y1_zHvWfp9E6zXx3E9xBZnuMOzdKHTNII-JWoU4_7-aW5gM17zLFNkr-WNqzFFGHHPqaA=s176-c-k-c0x00ffffff-no-rj', 'heart': False, 'reply': False, 'time_parsed': 1660508467.684335}\n",
      "{'cid': 'UgwJOWBoDR-AAvlokhd4AaABAg', 'text': 'I see you‚Äôre also re-visiting this trailer to remember the MCU at the height of its power. Great memories.', 'time': '4 months ago', 'author': '@jeffsavilleproductions7358', 'channel': 'UCAw9nFxu8CkEKASeqmPlGLg', 'votes': '5.7K', 'photo': 'https://yt3.ggpht.com/FHjvzppe_C6Phyi0Zoce3U4U9J0kaFMSU0UAQBU2RPMm6_uA1XM4pSlBKCRPj6gZgx2s02-o3-c=s176-c-k-c0x00ffffff-no-rj', 'heart': False, 'reply': False, 'time_parsed': 1681503667.685603}\n",
      "{'cid': 'UgyMhRi3aRR55ZDwIip4AaABAg', 'text': '5 years later... Still have the feels.', 'time': '4 months ago', 'author': '@bluescat581', 'channel': 'UCCqP0LmfAV29D01bQKSa30w', 'votes': '3.3K', 'photo': 'https://yt3.ggpht.com/QgWo5_0bNwvjfij3S4GRWIMATeU7udIDe0wN-lZysql2c4xHocwOTm_9CbO_IWDtxJKvG8618g=s176-c-k-c0x00ffffff-no-rj', 'heart': False, 'reply': False, 'time_parsed': 1681503667.686429}\n",
      "{'cid': 'UgxGJXmgHVNNxbsT84p4AaABAg', 'text': 'The way MCU built up Thanos for 10 years is one of the most successful characters development. The intimidation we felt back then in the theater was still fresh. Shame that they couldn‚Äôt do the same for Kang and they rushed too much on bringing the character to the light.', 'time': '1 month ago', 'author': '@ChrisFilmPresents', 'channel': 'UC2fyas9L3mnDbObCrHvBWyw', 'votes': '225', 'photo': 'https://yt3.ggpht.com/vxfjK8Gkb-ipe-ZvOgzmHADcJebM_KWwViDsMnkyQQF6HDGhWvEN1a46TxJWt2m7q4EOBNQJ_Xo=s176-c-k-c0x00ffffff-no-rj', 'heart': False, 'reply': False, 'time_parsed': 1689366067.687237}\n",
      "{'cid': 'Ugx_bfuifaKI0pdp2rt4AaABAg', 'text': 'I could rewatch this movie a million times and still never get bored', 'time': '4 months ago', 'author': '@kaseyhe4rts', 'channel': 'UCVeoZmYvsC8z-fAQRuCviQw', 'votes': '1.6K', 'photo': 'https://yt3.ggpht.com/TCs3fkkBpiKct355Swj9CgxNOYfZHCxouCeb4ctHImD7kffr8nSATAXjKEK8JHJQriAdhTNE=s176-c-k-c0x00ffffff-no-rj', 'heart': False, 'reply': False, 'time_parsed': 1681503667.688005}\n",
      "{'cid': 'Ugy3HLYmqyVjLWtXkPh4AaABAg', 'text': \"It's been five years, but still I couldn't able to forget what it felt like when I first watched this movie in theater with my dad. And my dad couldn't understand why I was crying so much even if it is not an emotional scene. I want to thank all the creators that made this possible ,the comic book writers, character designers, script writers, screenplay writers, producers, directors, production designers, costume designers, stunt men and women, music composers, camera men, crews, vfx artist and all the actors and actresses.\", 'time': '3 months ago', 'author': '@lalitbag402', 'channel': 'UCtv1ItTcVNJJ7Avvll6s-7A', 'votes': '583', 'photo': 'https://yt3.ggpht.com/jzhkAxFgmDx5ILS48ZePPx03RNc8zp0uHYpBAyFXENYzJJAh-2iM8FMsuwSl-3JQMyFp86ZDzA=s176-c-k-c0x00ffffff-no-rj', 'heart': False, 'reply': False, 'time_parsed': 1684095667.688734}\n",
      "{'cid': 'UgxZfaVMVTmk6MUofZV4AaABAg', 'text': 'No movie trailer will ever live up to the hype that this one did', 'time': '4 years ago', 'author': '@bluemilk7397', 'channel': 'UCrVSDTtsjsI4iwTw-u9D7zg', 'votes': '21K', 'photo': 'https://yt3.ggpht.com/ytc/AOPolaT6XA-HXxfDjZju2Y_16hUvo8Lf-QpKfZhIM86T=s176-c-k-c0x00ffffff-no-rj', 'heart': False, 'reply': False, 'time_parsed': 1565814067.689312}\n",
      "{'cid': 'Ugy7ftwHfsMZhm3VgKJ4AaABAg', 'text': 'Endgame was great, but Avengers: Infinity War will forever be the best Marvel movie ever made, IMO. It was everything a Marvel fan could want and more. Coming back to these trailers, the hype still feels real. God, I love this movie.', 'time': '4 months ago', 'author': '@viceregaldust3191', 'channel': 'UCyGHr2sI8zPi8L1indabQTw', 'votes': '1K', 'photo': 'https://yt3.ggpht.com/ytc/AOPolaRBWnPIKUejyqIy4p3cI9skta9Mn34TUqUKso1X=s176-c-k-c0x00ffffff-no-rj', 'heart': False, 'reply': False, 'time_parsed': 1681503667.690056}\n",
      "{'cid': 'UgybMnwKE5cfh4jsK-V4AaABAg', 'text': 'I am so glad I saw this in theatres\\nThe feeling was unmatched', 'time': '4 months ago', 'author': '@Evrimomono', 'channel': 'UCDQuAIYwzQH9Bwavxt-wEZQ', 'votes': '548', 'photo': 'https://yt3.ggpht.com/ytc/AOPolaRV506dHd3Mf198pUyoOH5fIH1BhgZqm4zpF97iOQ=s176-c-k-c0x00ffffff-no-rj', 'heart': False, 'reply': False, 'time_parsed': 1681503667.690768}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[53], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[39mfor\u001b[39;00m comment \u001b[39min\u001b[39;00m islice(comments, \u001b[39m10\u001b[39m):\n\u001b[1;32m      6\u001b[0m     \u001b[39mprint\u001b[39m(comment)\n\u001b[0;32m----> 7\u001b[0m c1 \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39;49m(comments)\n\u001b[1;32m      8\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mlen\u001b[39m(c1))\n",
      "File \u001b[0;32m~/miniconda/envs/pytorch_metal/lib/python3.10/site-packages/youtube_comment_downloader/downloader.py:78\u001b[0m, in \u001b[0;36mYoutubeCommentDownloader.get_comments_from_url\u001b[0;34m(self, youtube_url, sort_by, language, sleep)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[39mwhile\u001b[39;00m continuations:\n\u001b[1;32m     77\u001b[0m     continuation \u001b[39m=\u001b[39m continuations\u001b[39m.\u001b[39mpop()\n\u001b[0;32m---> 78\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49majax_request(continuation, ytcfg)\n\u001b[1;32m     80\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m response:\n\u001b[1;32m     81\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda/envs/pytorch_metal/lib/python3.10/site-packages/youtube_comment_downloader/downloader.py:35\u001b[0m, in \u001b[0;36mYoutubeCommentDownloader.ajax_request\u001b[0;34m(self, endpoint, ytcfg, retries, sleep)\u001b[0m\n\u001b[1;32m     31\u001b[0m data \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mcontext\u001b[39m\u001b[39m'\u001b[39m: ytcfg[\u001b[39m'\u001b[39m\u001b[39mINNERTUBE_CONTEXT\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[1;32m     32\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mcontinuation\u001b[39m\u001b[39m'\u001b[39m: endpoint[\u001b[39m'\u001b[39m\u001b[39mcontinuationCommand\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mtoken\u001b[39m\u001b[39m'\u001b[39m]}\n\u001b[1;32m     34\u001b[0m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(retries):\n\u001b[0;32m---> 35\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msession\u001b[39m.\u001b[39;49mpost(url, params\u001b[39m=\u001b[39;49m{\u001b[39m'\u001b[39;49m\u001b[39mkey\u001b[39;49m\u001b[39m'\u001b[39;49m: ytcfg[\u001b[39m'\u001b[39;49m\u001b[39mINNERTUBE_API_KEY\u001b[39;49m\u001b[39m'\u001b[39;49m]}, json\u001b[39m=\u001b[39;49mdata)\n\u001b[1;32m     36\u001b[0m     \u001b[39mif\u001b[39;00m response\u001b[39m.\u001b[39mstatus_code \u001b[39m==\u001b[39m \u001b[39m200\u001b[39m:\n\u001b[1;32m     37\u001b[0m         \u001b[39mreturn\u001b[39;00m response\u001b[39m.\u001b[39mjson()\n",
      "File \u001b[0;32m~/miniconda/envs/pytorch_metal/lib/python3.10/site-packages/requests/sessions.py:637\u001b[0m, in \u001b[0;36mSession.post\u001b[0;34m(self, url, data, json, **kwargs)\u001b[0m\n\u001b[1;32m    626\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpost\u001b[39m(\u001b[39mself\u001b[39m, url, data\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, json\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    627\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Sends a POST request. Returns :class:`Response` object.\u001b[39;00m\n\u001b[1;32m    628\u001b[0m \n\u001b[1;32m    629\u001b[0m \u001b[39m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    634\u001b[0m \u001b[39m    :rtype: requests.Response\u001b[39;00m\n\u001b[1;32m    635\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 637\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrequest(\u001b[39m\"\u001b[39;49m\u001b[39mPOST\u001b[39;49m\u001b[39m\"\u001b[39;49m, url, data\u001b[39m=\u001b[39;49mdata, json\u001b[39m=\u001b[39;49mjson, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda/envs/pytorch_metal/lib/python3.10/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[39m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtimeout\u001b[39m\u001b[39m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mallow_redirects\u001b[39m\u001b[39m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[39m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(prep, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49msend_kwargs)\n\u001b[1;32m    591\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/miniconda/envs/pytorch_metal/lib/python3.10/site-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m start \u001b[39m=\u001b[39m preferred_clock()\n\u001b[1;32m    702\u001b[0m \u001b[39m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[39m=\u001b[39m adapter\u001b[39m.\u001b[39;49msend(request, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    705\u001b[0m \u001b[39m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    706\u001b[0m elapsed \u001b[39m=\u001b[39m preferred_clock() \u001b[39m-\u001b[39m start\n",
      "File \u001b[0;32m~/miniconda/envs/pytorch_metal/lib/python3.10/site-packages/requests/adapters.py:486\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    483\u001b[0m     timeout \u001b[39m=\u001b[39m TimeoutSauce(connect\u001b[39m=\u001b[39mtimeout, read\u001b[39m=\u001b[39mtimeout)\n\u001b[1;32m    485\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 486\u001b[0m     resp \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49murlopen(\n\u001b[1;32m    487\u001b[0m         method\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mmethod,\n\u001b[1;32m    488\u001b[0m         url\u001b[39m=\u001b[39;49murl,\n\u001b[1;32m    489\u001b[0m         body\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mbody,\n\u001b[1;32m    490\u001b[0m         headers\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mheaders,\n\u001b[1;32m    491\u001b[0m         redirect\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    492\u001b[0m         assert_same_host\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    493\u001b[0m         preload_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    494\u001b[0m         decode_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    495\u001b[0m         retries\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_retries,\n\u001b[1;32m    496\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    497\u001b[0m         chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[1;32m    498\u001b[0m     )\n\u001b[1;32m    500\u001b[0m \u001b[39mexcept\u001b[39;00m (ProtocolError, \u001b[39mOSError\u001b[39;00m) \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m    501\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m(err, request\u001b[39m=\u001b[39mrequest)\n",
      "File \u001b[0;32m~/miniconda/envs/pytorch_metal/lib/python3.10/site-packages/urllib3/connectionpool.py:714\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    711\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prepare_proxy(conn)\n\u001b[1;32m    713\u001b[0m \u001b[39m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[0;32m--> 714\u001b[0m httplib_response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_request(\n\u001b[1;32m    715\u001b[0m     conn,\n\u001b[1;32m    716\u001b[0m     method,\n\u001b[1;32m    717\u001b[0m     url,\n\u001b[1;32m    718\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout_obj,\n\u001b[1;32m    719\u001b[0m     body\u001b[39m=\u001b[39;49mbody,\n\u001b[1;32m    720\u001b[0m     headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    721\u001b[0m     chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[1;32m    722\u001b[0m )\n\u001b[1;32m    724\u001b[0m \u001b[39m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[1;32m    725\u001b[0m \u001b[39m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[1;32m    726\u001b[0m \u001b[39m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[1;32m    727\u001b[0m \u001b[39m# mess.\u001b[39;00m\n\u001b[1;32m    728\u001b[0m response_conn \u001b[39m=\u001b[39m conn \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m release_conn \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda/envs/pytorch_metal/lib/python3.10/site-packages/urllib3/connectionpool.py:466\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    461\u001b[0m             httplib_response \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39mgetresponse()\n\u001b[1;32m    462\u001b[0m         \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    463\u001b[0m             \u001b[39m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[1;32m    464\u001b[0m             \u001b[39m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[1;32m    465\u001b[0m             \u001b[39m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[0;32m--> 466\u001b[0m             six\u001b[39m.\u001b[39;49mraise_from(e, \u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    467\u001b[0m \u001b[39mexcept\u001b[39;00m (SocketTimeout, BaseSSLError, SocketError) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    468\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_raise_timeout(err\u001b[39m=\u001b[39me, url\u001b[39m=\u001b[39murl, timeout_value\u001b[39m=\u001b[39mread_timeout)\n",
      "File \u001b[0;32m<string>:3\u001b[0m, in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "File \u001b[0;32m~/miniconda/envs/pytorch_metal/lib/python3.10/site-packages/urllib3/connectionpool.py:461\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m    459\u001b[0m     \u001b[39m# Python 3\u001b[39;00m\n\u001b[1;32m    460\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 461\u001b[0m         httplib_response \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49mgetresponse()\n\u001b[1;32m    462\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    463\u001b[0m         \u001b[39m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[1;32m    464\u001b[0m         \u001b[39m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[1;32m    465\u001b[0m         \u001b[39m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[1;32m    466\u001b[0m         six\u001b[39m.\u001b[39mraise_from(e, \u001b[39mNone\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniconda/envs/pytorch_metal/lib/python3.10/http/client.py:1374\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1372\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1373\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1374\u001b[0m         response\u001b[39m.\u001b[39;49mbegin()\n\u001b[1;32m   1375\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m:\n\u001b[1;32m   1376\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/miniconda/envs/pytorch_metal/lib/python3.10/http/client.py:318\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[39m# read until we get a non-100 response\u001b[39;00m\n\u001b[1;32m    317\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 318\u001b[0m     version, status, reason \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_read_status()\n\u001b[1;32m    319\u001b[0m     \u001b[39mif\u001b[39;00m status \u001b[39m!=\u001b[39m CONTINUE:\n\u001b[1;32m    320\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda/envs/pytorch_metal/lib/python3.10/http/client.py:279\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_read_status\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 279\u001b[0m     line \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfp\u001b[39m.\u001b[39;49mreadline(_MAXLINE \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m), \u001b[39m\"\u001b[39m\u001b[39miso-8859-1\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    280\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(line) \u001b[39m>\u001b[39m _MAXLINE:\n\u001b[1;32m    281\u001b[0m         \u001b[39mraise\u001b[39;00m LineTooLong(\u001b[39m\"\u001b[39m\u001b[39mstatus line\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda/envs/pytorch_metal/lib/python3.10/socket.py:705\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    703\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    704\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 705\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sock\u001b[39m.\u001b[39;49mrecv_into(b)\n\u001b[1;32m    706\u001b[0m     \u001b[39mexcept\u001b[39;00m timeout:\n\u001b[1;32m    707\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_timeout_occurred \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda/envs/pytorch_metal/lib/python3.10/ssl.py:1274\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1270\u001b[0m     \u001b[39mif\u001b[39;00m flags \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m   1271\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1272\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m\n\u001b[1;32m   1273\u001b[0m           \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m)\n\u001b[0;32m-> 1274\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread(nbytes, buffer)\n\u001b[1;32m   1275\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1276\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m~/miniconda/envs/pytorch_metal/lib/python3.10/ssl.py:1130\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1128\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1129\u001b[0m     \u001b[39mif\u001b[39;00m buffer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1130\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sslobj\u001b[39m.\u001b[39;49mread(\u001b[39mlen\u001b[39;49m, buffer)\n\u001b[1;32m   1131\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1132\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sslobj\u001b[39m.\u001b[39mread(\u001b[39mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from itertools import islice\n",
    "from youtube_comment_downloader import *\n",
    "\n",
    "def getCommentsFromYouTubeVideo():\n",
    "    downloader = YoutubeCommentDownloader()\n",
    "    comments = downloader.get_comments_from_url('https://www.youtube.com/watch?v=6ZfuNTqbHE8', sort_by=SORT_BY_POPULAR)\n",
    "    for comment in islice(comments, 10):\n",
    "        comments = list(comments)\n",
    "    return comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comment_text = []\n",
    "text_file = 'tweets.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readFromFile():\n",
    "    comment_text = []\n",
    "    # Read tweets from the text file\n",
    "    with open(text_file, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            tweet_text = line.strip()  # Remove newline character\n",
    "            comment_text.append(tweet_text)\n",
    "    return comment_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comment_text = getCommentsFromYouTubeVideo()\n",
    "comment_text = readFromFile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import TFAutoModelForSequenceClassification\n",
    "from transformers import AutoTokenizer, AutoConfig\n",
    "import numpy as np\n",
    "from scipy.special import softmax\n",
    "\n",
    "annotatedStrings = []\n",
    "# Preprocess text (username and link placeholders)\n",
    "def preprocess(text):\n",
    "    new_text = []\n",
    "    for t in text.split(\" \"):\n",
    "        t = '@user' if t.startswith('@') and len(t) > 1 else t\n",
    "        t = 'http' if t.startswith('http') else t\n",
    "        new_text.append(t)\n",
    "    return \" \".join(new_text)\n",
    "\n",
    "def setSentiment(scores):\n",
    "    return_value = 0\n",
    "\n",
    "    # Check conditions and set return value accordingly\n",
    "    if scores[0] > scores[1] and scores[0] > scores[2]:\n",
    "        return_value = -1\n",
    "        return return_value\n",
    "    elif scores[1] > scores[0] and scores[1] > scores[2]:\n",
    "        return_value = 0\n",
    "        return return_value\n",
    "    else:\n",
    "        return_value = 1\n",
    "        return return_value\n",
    "\n",
    "def callModel(text):\n",
    "    MODEL = f\"cardiffnlp/twitter-roberta-base-sentiment-latest\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "    config = AutoConfig.from_pretrained(MODEL)\n",
    "    # PT\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(MODEL)\n",
    "    #model.save_pretrained(MODEL)\n",
    "    # \\text = \"Covid cases are increasing fast!\"\n",
    "    text = preprocess(text)\n",
    "    encoded_input = tokenizer(text, return_tensors='pt')\n",
    "    output = model(**encoded_input)\n",
    "    scores = output[0][0].detach().numpy()\n",
    "    scores = softmax(scores)\n",
    "    sentiment = setSentiment(scores)\n",
    "    annotatedStrings.append({\"text\": text, \"sentiment\": sentiment})\n",
    "\n",
    "# # TF\n",
    "# model = TFAutoModelForSequenceClassification.from_pretrained(MODEL)\n",
    "# model.save_pretrained(MODEL)\n",
    "# text = \"Covid cases are increasing fast!\"\n",
    "# encoded_input = tokenizer(text, return_tensors='tf')\n",
    "# output = model(encoded_input)\n",
    "# scores = output[0][0].numpy()\n",
    "# scores = softmax(scores)\n",
    "# Print labels and scores\n",
    "# ranking = np.argsort(scores)\n",
    "# ranking = ranking[::-1]\n",
    "# for i in range(scores.shape[0]):\n",
    "#     l = config.id2label[ranking[i]]\n",
    "#     s = scores[ranking[i]]\n",
    "#     print(f\"{i+1}) {l} {np.round(float(s), 4)}\")\n",
    "\n",
    "for i in range(0, 10):\n",
    "# for comment in comment_text:\n",
    "    callModel(comment_text[i])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "\n",
    "# Sample social media text\n",
    "text = \"Hey! This is a #sample tweet with emojis üòÉüëç and some slang lol. Can't wait to try it!\"\n",
    "\n",
    "def preprocessText(text: str):\n",
    "    # Step 1: Lowercasing\n",
    "    text = text.lower()\n",
    "\n",
    "    # Step 2: Tokenization\n",
    "    tokens = word_tokenize(text)\n",
    "\n",
    "    # Step 3: Stop-word Removal\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    filtered_tokens = [word for word in tokens if word not in stop_words]\n",
    "\n",
    "    # Step 4: Handling Hashtags\n",
    "    hashtags = [word for word in filtered_tokens if word.startswith('#')]\n",
    "    filtered_tokens = [word for word in filtered_tokens if not word.startswith('#')]\n",
    "\n",
    "    # Step 5: Handling Emojis (Assuming you have a list of emoji patterns)\n",
    "    emoji_patterns = [r'üòÉ', r'üëç', r'üòÇ', r'üòä']  # Add more patterns as needed\n",
    "    filtered_tokens = [word for word in filtered_tokens if not any(re.search(pattern, word) for pattern in emoji_patterns)]\n",
    "\n",
    "    # Step 6: Handling Slang (Assuming you have a slang dictionary)\n",
    "    slang_dict = {'lol': 'laugh out loud', \"can't\": 'cannot'}  # Add more slang words\n",
    "    filtered_tokens = [slang_dict[word] if word in slang_dict else word for word in filtered_tokens]\n",
    "\n",
    "    # Step 7: Stemming/Lemmatization\n",
    "    stemmer = PorterStemmer()\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    processed_tokens = [stemmer.stem(lemmatizer.lemmatize(word)) for word in filtered_tokens]\n",
    "\n",
    "    # Final preprocessed text\n",
    "    preprocessed_text = ' '.join(processed_tokens)\n",
    "    print(preprocessed_text)\n",
    "    return preprocessed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infin war mcu peak . 5 year still chill everytim watch trailer . sad see mcu right .\n",
      "‚Äô back 5 years‚Ä¶ . 5 year trailer still give chill\n",
      "‚Äô believ ‚Äô alreadi 5 year ( liter half decad ) sinc came . still one best thing marvel ever releas\n",
      "movi trailer ever live hype one\n",
      "'s 5 year sinc masterpiec came . make sad know begin end someth truli beauti .\n",
      "came back 5 year feel hype like 1st time , know 'll ever get level excit mcu\n",
      "trailer alway special place heart ‚ù§\n",
      "ca n't believ 5 year ..\n",
      "still watch trailer give goosebump\n",
      "5 year later still get chill\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, 10):\n",
    "# for comment in comment_text:\n",
    "    annotatedStrings[i]['text'] = preprocessText(annotatedStrings[i]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': 'infin war mcu peak . 5 year still chill everytim watch trailer . sad see mcu right .',\n",
       "  'sentiment': -1},\n",
       " {'text': '‚Äô back 5 years‚Ä¶ . 5 year trailer still give chill', 'sentiment': 1},\n",
       " {'text': '‚Äô believ ‚Äô alreadi 5 year ( liter half decad ) sinc came . still one best thing marvel ever releas',\n",
       "  'sentiment': 1},\n",
       " {'text': 'movi trailer ever live hype one', 'sentiment': -1},\n",
       " {'text': \"'s 5 year sinc masterpiec came . make sad know begin end someth truli beauti .\",\n",
       "  'sentiment': -1},\n",
       " {'text': \"came back 5 year feel hype like 1st time , know 'll ever get level excit mcu\",\n",
       "  'sentiment': 1},\n",
       " {'text': 'trailer alway special place heart ‚ù§', 'sentiment': 1},\n",
       " {'text': \"ca n't believ 5 year ..\", 'sentiment': -1},\n",
       " {'text': 'still watch trailer give goosebump', 'sentiment': 1},\n",
       " {'text': '5 year later still get chill', 'sentiment': -1}]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotatedStrings"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_metal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
